{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from collections import OrderedDict\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_shot = 1\n",
    "n_class = 10\n",
    "n_local_update = 5\n",
    "batch_size = n_class\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(OmniglotNet, self).__init__()\n",
    "        \n",
    "        self.h=64\n",
    "        self.conv1 = nn.Conv2d(1, self.h, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.fc = nn.Linear(self.h, n_class)\n",
    "        \n",
    "        # init is very very important!!!\n",
    "        # no init version -> HASH:ef56239\n",
    "        init.xavier_normal_(self.conv1.weight)\n",
    "        init.constant_(self.conv1.bias, 0)\n",
    "        init.xavier_normal_(self.conv2.weight)\n",
    "        init.constant_(self.conv2.bias, 0)\n",
    "        init.xavier_normal_(self.conv3.weight)\n",
    "        init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        init.constant_(self.bn1.weight, 1)\n",
    "        init.constant_(self.bn1.bias, 0)\n",
    "        init.constant_(self.bn2.weight, 1)\n",
    "        init.constant_(self.bn2.bias, 0)\n",
    "        init.constant_(self.bn3.weight, 1)\n",
    "        init.constant_(self.bn3.bias, 0)\n",
    "        \n",
    "        init.normal_(self.fc.weight, 0, 0.01)\n",
    "        init.constant_(self.fc.bias, 1) # not 0 but 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # for MAML local optimization\n",
    "    def manual_forward(self, x, params):\n",
    "        \n",
    "        x = F.conv2d(x, params['conv1.weight'].to(device), params['conv1.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn1.weight'], params['bn1.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv2.weight'].to(device), params['conv2.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn2.weight'], params['bn2.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv3.weight'].to(device), params['conv3.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn3.weight'], params['bn3.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = F.linear(x, params['fc.weight'].to(device), params['fc.bias'].to(device))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, device, train_data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_data_loader.dataset)\n",
    "    train_acc /= len(train_data_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test(model, device, test_data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_acc /= len(test_data_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedDataset(Dataset):\n",
    "    def __init__(self, path_to_chars, train, train_indices, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = NotImplementedError\n",
    "        \n",
    "        for label_i, (path_to_label, train_index) in enumerate(zip(path_to_chars, train_indices)):\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))\n",
    "            if train:\n",
    "                chars = chars[train_index]\n",
    "            else:#omniの一つの文字が20画像あるが、trainで使わなかったやつをtestにしている\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample[0], sample[1]\n",
    "        image = image / 255\n",
    "        image = (image-0.92208)/0.25140\n",
    "        image = image.reshape([28,28, 1])\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.array(image, np.float32)\n",
    "\n",
    "        return [torch.from_numpy(image), torch.from_numpy(label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [ 8],\n",
       "       [14],\n",
       "       [ 4],\n",
       "       [ 0],\n",
       "       [12],\n",
       "       [11],\n",
       "       [12]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_task_train_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([5, 4, 6, 1, 9, 0, 8, 3, 2, 7])\n",
      "\n",
      "local_task_test_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([2, 1, 7, 6, 9, 7, 5, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "#一つの文字に20画像あるうちtrainに使うindexを設定。適当な10文字をつかい、学習時は1文字中1つの画像しか見れな。\n",
    "# これはtrain時に見せる1/20とtest時の19/20を示す\n",
    "train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "\n",
    "#10文字を指定\n",
    "path_to_chars = [\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character08',\n",
    "    '../data/omniglot_mini/images_background/N_Ko/character05',\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character01',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character04',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character21',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character03',\n",
    "    '../data/omniglot_mini/images_background/Gujarati/character35',\n",
    "    '../data/omniglot_mini/images_background/Bengali/character10',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character18',\n",
    "    '../data/omniglot_mini/images_background/Armenian/character17'\n",
    "]\n",
    "\n",
    "print(\"local_task_train_data\")\n",
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=True,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_train_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "\n",
    "print(\"\\nlocal_task_test_data\")\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=False,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_test_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taskset and TaskLoader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taskset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TaskLoader(object):\n",
    "    def __init__(self, taskset, shuffle=True):\n",
    "        self.taskset = taskset\n",
    "        self.sample_iter = iter(np.random.permutation(np.arange(len(taskset))))\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        return self.taskset[next(self.sample_iter)]\n",
    "    def __len__(self):\n",
    "        return len(self.taskset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedTaskset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedTaskset(Taskset):\n",
    "    def __init__(self, path_to_omniglot, n_class, n_shot, meta_train):\n",
    "        \n",
    "        if meta_train:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_background/\")\n",
    "        else:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_evaluation/\")\n",
    "            \n",
    "        chars = []\n",
    "        \n",
    "        for path_to_lang in os.listdir(path_to_langs):\n",
    "            path_to_chars = os.path.join(path_to_langs, path_to_lang)\n",
    "            for path_to_char in os.listdir(path_to_chars):\n",
    "                chars.append(os.path.join(path_to_chars, path_to_char)) \n",
    "        \n",
    "        random.shuffle(chars)\n",
    "        tasks = list(chunked(chars, n_class))[:-1] # drop_last\n",
    "        \n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "        return {\"train\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=True,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True), \n",
    "                \"test\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=False,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True),\n",
    "                \"task\": self.tasks[idx] \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentTaskLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['../data/omniglot_mini/images_background/Latin/character05', '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character10', '../data/omniglot_mini/images_background/Hebrew/character10', '../data/omniglot_mini/images_background/Bengali/character39', '../data/omniglot_mini/images_background/N_Ko/character12', '../data/omniglot_mini/images_background/Balinese/character17', '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character25', '../data/omniglot_mini/images_background/Mkhedruli_(Georgian)/character13', '../data/omniglot_mini/images_background/Anglo-Saxon_Futhorc/character12', '../data/omniglot_mini/images_background/Cyrillic/character20']\n",
      "train\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAABRCAYAAAAZ1Ej0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATbklEQVR4nO3dfZQV5WHH8e/DrrgCYhBfeNlFfFfULhhcC4fWtNYurPWYBBON8VjPoWDkJEbbotYeT2JfctLQCGnP0bJUT0OiNUbSxiIv9SQ1LYWImC5RQAhvsrAsKpAAvsDu8vSPuXN39u59mTv33rkzc3+fc/aw3Je5z+/OM7PPPPPMM8Zai4iIiIgUb0i1CyAiIiISV2pIiYiIiASkhpSIiIhIQGpIiYiIiASkhpSIiIhIQGpIiYiIiARUUkPKGDPTGLPNGLPDGPNIuQoVJcoYf0nPB8qYFEnPmPR8oIw1yVob6AeoA3YCFwFDgU3ApKDLi+KPMsb/J+n5lLH6ZVNG5VPGZGUs9qeUHqkWYIe1dpe19iTwPHBrCcuLImWMv6TnA2VMiqRnTHo+UMaaVF/Ce8cDnZ7/7wOuz3yRMWYeMA9g+DDzySsuGVrCR4brogn1/ObYKaY2N9g9nT0Ad1ODGZOSL/XQMWBZ5uuSkrGW6ykkP2NS8qUe0raIMkbdns4e3j/cZ/K9ppSGVLYFD7rfjLW2HWgHmNrcYDesaSrhI8P1w/84zn+++iFLv30eLa2dHDpyAmowY1LyAdSN3fE+NbgOQRlLsfz4SABmjzhaluVlo23RkZSM2hbjm9GrpbWz4GtKaUjtA7zfTCPQVcLyIqdxbB2d+3sGPIQyxkqWfENJUD5I/jqE6mdsv+wiAGZ3dVTsM6qdsdLC2BabvzUfgDGL17Gmgusql6SvQ6iNjMUqZYzU68ClxpgLjTFDgTuAl8pTrGi4bnIDO3b3sHtvD6dOWVDG2PHmO3nSApxNgvJB8tchKGMSaFtMhlrIWKzAPVLW2l5jzJeBNTij+J+x1m4uW8kioL7e8A/fOJdZX+jinX09AC8oY7x48/X1WYDDScoHlVuHzQvnD3pszKJ1gZfX/eB0ADYteLLo9ya9nkLyM4axLf72nf8HwJ7F5Vyqf0lfh1AbGYtV0jxS1tqV1trLrLUXW2v/tlyFipK2G4fz9v9ewDVXnI4yxpOb71c/nwjQXeXiVETS1yEoYxJoW0yGWshYjFLGSImUxaR1d2V9/Hcm7ARgSeP6MIsjKdl6n4ZMnsSu2WcBsG3OUwWX0bxwfno57r+tiyann+988eoBr98y/fuByyvi7itamVzglSLlo1vEiIiIiAQU+x6p1nGTq3J1hpSudZxz1PjRkjO47N7XBz2/J/Xv6h2nAzBz2ImQSiZAju2quG1t04In0z1Qmctru+l2mm57a8Bjq3ecrvUsUoPcKUagstOMVELkGlLuH9dKvkcNr+pY/aHTIFp0yZUDHt99y1K4ZfDr3fW6+MpmAGa+s6GyBQzo8qfvA2DiY+upu+ryAc+tfOUH1ShSLOi7EZFpm2YDMHLWzvRj7al/i/1b3XbT7YMeu//H/w5U9kBcp/ZEREREAopcj1SxLVCd2ouHG+bNo2GF06O0fcl1QKonKg93IHLm6Z+ocHvMJuIMcO188epBZXVfk62Ozmq7k1MdW3Iuf8jkSQCsWvlcWcpbDt716CplWoOoy+zt1v5GpLzcnqi6qy5P91K7253f7c3tierbvG3Qc+4ZkEVU7myUeqREREREAopcj1QQbms0zmMuJq27K2fPS7ZWdL5xYV0LpvPmg9HqHWhYscGTw99RgXspfFQvZR68XjoG3ShhVtudALSOy7aELXl7c9z35OvVCotbhgY2pMs8/l+2Av3TGtzwq3l878knAJg7YcagZcRpO823fd3ccjMAL294OazihOaaRfMZt3DwtBdu73ASpqfItW7V01hd3v2Cuy5ax032tb352afMarszvU/1ruvM+hCkHiSiIRVHmV2RTbw1aKCy+1zzt+az6SHnD6270usbx+esWK3jYOqvnQHQGx8vPNdPGJxstbejck/LeTfWgRtq7u/EuzOJCqdMqTIvGPhc6ziYu8JpQNVddjEAK19dnt4R9mbpdo8S96oh9756MHgddD8wnTGL1w14bOnetUyoHxFmUcvOzTKOdYP2Q9B/ej3zoGbe9l2Rv8Kq7VPOYOa+7alTSKNGwbjzBr6o692y/EGNCu+BedRz5Cvfmq6OdOOn1BuHr1r5XHpf5C5z3vZdZdnP6tSeiIiISEDqkaoS95LMD045UwI4reyBLfN8LeTdi0flfO7Q3GmMXpqaDfzx0spZLnE4nVNp/Uf60T5CzKftptt9rcuVry5P/+7W1abb9lesXKW4Yd48gPQg+kNzp+XtyXWPYN2ejrkTYM9fTwP8zfYeJTMvaEn9dhLI6HHMw903tV92EY9GPLvbE7V071qAnL2He3uPA/2npd2MR1ddzPrm5VnfI/HinsXx1t/ZWea3g+L+ZqlHSkRERCSg2PdIdS2YTtM/b612MYrWPzmYj0nCTHHL3vj4U7QudVrccRrgK9HXt3lbzsHvX3x7H89e0ViNYgX2xomT6Z6o/gHVeXpWPNui2+t2775p0OL0ALc9H4/t7Y0TTg+U7XH+/eLb+4p6v3dcScPhIndQIcns0S80js193s3mjqcZOWvnoItIJN7c3sm5E2ak7/XaRPBpdtQjJSIiIhJQ7Huk+q4/St/CI9UuhgTgHglAMi6rLrdrFs0HnCuposK5isY50s+8iubuke9zd9f7VStbEI9e2JL+PWgdXNK4nkkvpo5qIzp5bCZvbiDdk/gs+XsU6xvHA55xbyUcxYcl6FVr3vE0zQudbTGOk866Y7/ieGXppHV3petYOa8OzfZdfPxHzjYxfPdvil5e7BtStWDTgied0wcAfATEu+Hh/iH27oQzL6tOwiXlpZj6tfsYt9RpQEXp8mXv6ZKoX/aej7c7v6jv12Z/OOpznuXinaYiU7b7lrlTWHgvHIhj46IY3Q9MT8+VljnlR1Rtmf79dF30zuk2b/suAIYPcYaURP0G4d4Dk3LOp/fhqZPp388a7vxN/Vl78L+pOrUnIiIiEpB6pCKo/0jQOfqbtml2+n5EEzecUaVSlc49FeTKN2P73AkzItUTU2mZE7SOZj3f2O3e025olUrVzy3Lnp5ziu6JWt3yTwDMZfBs59XiLVMUZo6vljkrXsn5XNQHzEt+bn1e/aEzxc6iS64cMNkswMwq1Hl3upGftbfnfI235/vf9jn7ns80OqfeynFngdt+/wup33aWZWoL9UiJiIiIBKQeqQjKvIP1yFk7ObrKGcuwpDG+E8NlHg1l405ame0u3nHk3msPtmQ9wu8/8nLyDrynWfV7olyfPH1o6t/ix0VFcaybW6ale9cOmoAxW8+UOxB1zOJ18NDg5Xlv3eSovd6tqClXD+Omh56kdXG8xr55ueOgZnZ19I8NrOJFEe5gbj+3ZOl+cDrDhjjrsX/KDXy/P7edJbx3sNg3pLyD6kq9F0+1ZZ76cvmdbTjKrlk0P331Wb4d3M47zgZg4mOhFKtipm1yZr0e2bEFyJ05642PJTQT6kek14H3BtPugYvb7X/gro8BuHDF4GU0L5zPmFTdTuKNjEUqKX+Dd/Bz7uvv3TeNn//rFKD6Fzzo1J6IiIhIQLHvkfJyTx1l3jsnbvJdkhxX4xauS58eydfrkr5f15zKl6kU9+6bxp4W57JZ7xGV2908MtV17PZsqKcp+latfA5wBrO6F3e4vd3bu5YN+D/0D+Ids2gd3Q9MTz2q9SwShiWN62HB+pKW0XbT7elhJKWcClaPlIiIiEhAieqRirtZw5xZoWeXoSeqv3UdnSPkfJe7xoU7S7DbGwXZBz26E9/NHhGd71/8eXnDy+nxim4vt3vJNexPX77t3qMPnAHJcVRqL37bVb9H3xHnzhJRmz5i5gVOD/jqdzYUeGV+lz99HxMpredD+rkX3ZQ2WDxaCjakjDFNwDJgDHAKaLfWfscYczbwA2AisAf4vLU2lvdq6dzfwz33v0v3u70MGWKYe9dI7p/7CQ4f6eOOL3XzTmcvB9/rxRgzKo4Z/eS7oKme3t4c0zbHgN+MQF21yxpU0uspJD+jtkVti3FRCxnLxU+PVC/wZ9baXxhjzgTeMMa8AtwD/MRa+01jzCPAI8DDlStqbqUeCdXXGxZ+bTTX/lYDx46f4rrWTv7gd4fx3ReOcuOMYTz8lVFMmLKbY8f7Kppx2JDKXO7uJ9/f/eMRvrP01xX5/DD4zfiT//5oTCmf471DvPdega5K3ronKvW0kqKS0b3yd3bGJdcwsCcKitv/RGVb7L+U3OkV8DNJIsAbJ5xba/Tfq+9IesoOt/c7rG2xENvjlLXUe81NfGw93Q8OHAMXlXpaKnd9utObeCUlYxgKNqSstQeAA6nfjxljtgLjgVuBT6Ve9l3gVWL6ZY49v56x5ztfxZkjhnDFpUPZ393LS2s+4KfLnXlhRo+qY39336eJYUY/+e7+/Jk8/veHK1qOYmeQXnb0HN/L9pvx0W8cGlVksXMK+36Hca+nmX+MsolqxsyGBxBo5vmobIuubHPzZNs+c80/lG1qlmpsi/kEbUB5T+dmXl4f1XpaSOY9Id0GcbZ1HlbGat4Qum/zNl8XQRVS1GBzY8xEYArwGnB+qpHlNrbOy/GeecaYjcaYje8d6gtc0LDs6eyh480TXH9tAwff60tXpNNOM5CAjLnyjT2/nt6+7KcT4pQP8mckx8FDUjImpZ5C8jNqW9S2qIzJ4HuwuTFmBLAceMBae9QY4+t91tp2oB1ganNDpE/8H//gFJ+b080Tf3UOI8/038aMS8Zq5lvT1ZE+mvfbM/XsFY0AmNP8H/EnfR1CfDMWc8QZ1YxHV12cnhoh2+kQv6KWz9vjlm0QcBNOT5R75wE/9+GLSka/+xv3FKA70z3sL/i+qGQsVjGnoyuV0Z0yZMwiZzLb1kXVGXz+3j0flrwMX9+KMeY0nEbUs9baH6UePmiMGZt6fizwbsmlqaKeHsttcw5w52dH8Nmbna7g88+t48DB3vTzxDhjoXwHDvZSX+evcRxVfjLijPmLraTXU0h+Rm2L2hbjohYyloOfq/YM8DSw1Vr7hOepl4A/Br6Z+vfHFSlhCKy1/MmfvsuVlw7lwS/1n7a/5Q+Hs+yFYzz8lVEcOtIHMc3oJ9+yF47xibMqO61Y5l28vUe+7pGuy3uvPT+XL/vNCMR2RH3S6ylEP+P65uUDJuUsVlS2xVwK91QU7smIyraYa3+Tua8BoOvd9DQOme/PNgYu6vW0HCqd8ZmvLgbg0cUtBV5Zfu6k13NWvFKWKWqMtfl7FY0xM4D/Ad7Emf4A4FGccVIvABOAvcDnrLV5R0hObW6wG9Y0lVrmslv72kfc8On9XHPlUIak9l9/8xejuX5KA3fc283e/c5lnseO29FxzOgn34Tx9Rw63EfH5hN5D4XLmS/fDTQ7X7y6qMHcfjP+dO1HHdbaKfmWFcV1CMmvpxCPjMVeNOEV1W2xnKKwLWYbNF9o3qJi1mcc6mmpaiGjHy2tnWzc9HHebdHPVXtrgVwLuTFIwaJmxvVn0HfgkqzPvfJD5+qE1JcZzqU0ZeYnHzgZ48pvxrqxO2I76jHp9RSSn1HborbFuKiFjOWimc2latI9Tl3Zno3WLMkiEm9Rm3ldkkP32hMREREJSA0pERERkYDUkBIREREJSA0pERFJFI2HkjCpISUiIiISkBpSIiIiIgEVnJCzrB9mzHvAB8D7oX1ocOcwsJwXWGvPLfSmpGeMWT5IfkbV0xySnjHm+SD5GVVPU5KeMdSGFIAxZqO1dmqoHxpAKeVMesa45IPkZ1Q9rdx7w6R6Wpn3hkkZK/feMAUpp07tiYiIiASkhpSIiIhIQNVoSLVX4TODKKWcSc8Yl3yQ/Iyqp5V7b5hUTyvz3jApY+XeG6aiyxn6GCkRERGRpNCpPREREZGA1JASERERCSi0hpQxZqYxZpsxZocx5pGwPrcQY0yTMea/jDFbjTGbjTFfTT3+dWPMfmNMR+qnzceylLFKypUxqvkg+RlVT5UxYzmRzAfJz6h6WlxGrLUV/wHqgJ3ARcBQYBMwKYzP9lG2scC1qd/PBLYDk4CvA3+ujLWTMcr5aiGj6qkyxiFfLWRUPfWf0VobWo9UC7DDWrvLWnsSeB64NaTPzstae8Ba+4vU78eArcD4AItSxioqU8bI5oPkZ1Q9LUrSM0Y2HyQ/o+ppccJqSI0HOj3/30fAAleSMWYiMAV4LfXQl40xvzTGPGOMGVXg7coYESVkjEU+SH5G1dOazxiLfJD8jKqnBTOG1pAyWR6L1LwLxpgRwHLgAWvtUeAp4GJgMnAA+HahRWR5TBlDVmLGyOeD5GdUPVVGYpAPkp9R9dRXxtAaUvuAJs//G4GukD67IGPMaThf5LPW2h8BWGsPWmv7rLWngKU4XZT5KGOVlSFjpPNB8jOqnipjSqTzQfIzqp76zhhaQ+p14FJjzIXGmKHAHcBLIX12XsYYAzwNbLXWPuF5fKznZZ8B3iqwKGWsojJljGw+SH5G1dM0ZYxwPkh+RtXTND8Zw7lqzzqj4ttwRsXvBP4yrM/1Ua4ZOF2NvwQ6Uj9twPeAN1OPvwSMVcbkZ4xqvlrIqHqqjHHIVwsZVU+Ly6hbxIiIiIgEpJnNRURERAJSQ0pEREQkIDWkRERERAJSQ0pEREQkIDWkRERERAJSQ0pEREQkIDWkRERERAL6f7vUROQw+BNxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 5, 7, 6, 3, 8, 0, 4, 2, 1])\n",
      "test\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 6, 5, 9, 5, 9, 5, 0, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "meta_train_task_loader = TaskLoader(\n",
    "    OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot)\n",
    ")\n",
    "\n",
    "print(len(meta_train_task_loader.taskset))\n",
    "\n",
    "for i, meta_train_task in enumerate(meta_train_task_loader):\n",
    "    print(meta_train_task[\"task\"])\n",
    "    print(\"train\")\n",
    "    local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "    for data, target in local_task_train_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "    print(\"test\")\n",
    "    local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "    for data, target in local_task_test_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.1\n",
    "        self.momentum = 0.5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.master_net = OmniglotNet(n_class).to(self.device)\n",
    "        self.master_opt = optim.Adam(self.master_net.parameters(), lr=0.001)\n",
    "        self.keys = self.master_net.state_dict().keys()\n",
    "    \n",
    "    def copy_params(self, from_net, to_net):\n",
    "        params = {k: v for k, v in from_net.state_dict().items() if k in self.keys}\n",
    "        to_net.load_state_dict(params, strict=False)\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.master_net.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.master_net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def meta_test(self):\n",
    "        \n",
    "        meta_test_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=False, n_class=n_class, n_shot=n_shot))\n",
    "\n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_test_task_loader, desc=\"Meta Test \", ncols=10) as _tqdm:\n",
    "            for meta_test_task in _tqdm:\n",
    "\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "                faster_opt = optim.SGD(faster_net.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_test_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_test_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    _train_loss, _train_acc = train(\n",
    "                        faster_net, self.device, local_task_train_data_loader, faster_opt, epoch)\n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task test\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                _test_loss, _test_acc = test(faster_net, self.device, local_task_test_data_loader)\n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        return np.mean(test_loss), np.mean(test_acc)\n",
    "\n",
    "    \n",
    "    def meta_train(self):\n",
    "        \n",
    "        meta_train_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot))\n",
    "    \n",
    "        meta_grads = []\n",
    "        \n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_train_task_loader, desc=\"Meta Train\", ncols=10) as _tqdm:\n",
    "            for meta_train_task in _tqdm:\n",
    "                \n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                faster_net.forward = NotImplementedError # goodbye!\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "\n",
    "                # faster_params = OrderedDict((name, param) for (name, param) in faster_net.named_parameters())\n",
    "                master_params = OrderedDict((name, param) for (name, param) in self.master_net.named_parameters())\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                first_train_for_this_task = True\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    \n",
    "                    _train_loss = 0 # For tqdm.\n",
    "                    _train_acc = 0 # For tqdm.\n",
    "                    \n",
    "                    for data, target in local_task_train_data_loader:\n",
    "                        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                        if first_train_for_this_task:\n",
    "                            # manual predict\n",
    "                            output = self.master_net(data)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "                            grads = torch.autograd.grad(loss, self.master_net.parameters(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(master_params.items(), grads)\n",
    "                            )\n",
    "                            \n",
    "                            first_train_for_this_task = False\n",
    "\n",
    "                        else:\n",
    "                            # manual predict\n",
    "                            output = faster_net.manual_forward(data, faster_params)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                                                        \n",
    "                            grads = torch.autograd.grad(loss, faster_params.values(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "                            )\n",
    "\n",
    "                    _train_loss /= len(local_task_train_data_loader.dataset)\n",
    "                    _train_acc /= len(local_task_train_data_loader.dataset)\n",
    "                    \n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                \n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task test\n",
    "                # ----------------------------------------------------------------\n",
    "                \n",
    "                _test_loss = 0 # For logging.\n",
    "                _test_acc = 0 # For logging.\n",
    "                \n",
    "                for data, target in local_task_test_data_loader:\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                    output = faster_net.manual_forward(data, faster_params)\n",
    "                    loss = F.nll_loss(output, target) # test_loss計算するとこまではfaster_net\n",
    "\n",
    "                    # differentiates test_loss by master_net params\n",
    "                    grads = torch.autograd.grad(loss, self.master_net.parameters(), retain_graph=True)\n",
    "                    grads = {name:g for ((name, _), g) in zip(faster_net.named_parameters(), grads)}\n",
    "                    meta_grads.append(grads)\n",
    "\n",
    "                    pred = output.max(1, keepdim=True)[1]\n",
    "                    acc = pred.eq(target.view_as(pred)).sum()\n",
    "                    \n",
    "                    _test_loss += loss.item()\n",
    "                    _test_acc += acc.item()\n",
    "                \n",
    "                _test_loss /= len(local_task_test_data_loader.dataset)\n",
    "                _test_acc /= len(local_task_test_data_loader.dataset)  \n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # end all tasks\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # meta update\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        meta_grads = {k: sum(grads[k] for grads in meta_grads) for k in meta_grads[0].keys()}\n",
    "        \n",
    "        # using data,target from somewhere\n",
    "        dumy_output = self.master_net(data)\n",
    "        dumy_loss = F.nll_loss(dumy_output, target)\n",
    "        \n",
    "        # after dumy_loss.backward, rewrite grads\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward(retain_graph=True)\n",
    "\n",
    "        hooks = []\n",
    "        for (k,v) in self.master_net.named_parameters():\n",
    "            def get_closure():\n",
    "                key = k\n",
    "                def replace_grad(grad):\n",
    "                    return meta_grads[key]\n",
    "                return replace_grad\n",
    "            hooks.append(v.register_hook(get_closure()))\n",
    "\n",
    "        # Compute grads for current step, replace with summed gradients as defined by hook\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward()\n",
    "\n",
    "        # Update the net parameters with the accumulated gradient according to optimizer\n",
    "        self.master_opt.step()\n",
    "\n",
    "        # Remove the hooks before next training phase\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        return np.mean(test_loss), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.49it/s, epoch=5, train_loss=0.058, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  (meta-test-task) test_loss: 1.840778, test_acc: 0.457004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:22<00:00,  4.67s/it, epoch=5, train_loss=0.103, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:19<00:00,  3.39it/s, epoch=5, train_loss=0.048, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 (meta-train-task) test_loss: 0.193764, test_acc: 0.501700\n",
      "# 1  (meta-test-task) test_loss: 1.753461, test_acc: 0.502429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:25<00:00,  4.72s/it, epoch=5, train_loss=0.100, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:19<00:00,  3.39it/s, epoch=5, train_loss=0.060, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2 (meta-train-task) test_loss: 0.186496, test_acc: 0.544024\n",
      "# 2  (meta-test-task) test_loss: 1.690205, test_acc: 0.532955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:27<00:00,  4.56s/it, epoch=5, train_loss=0.103, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.48it/s, epoch=5, train_loss=0.050, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3 (meta-train-task) test_loss: 0.180571, test_acc: 0.564857\n",
      "# 3  (meta-test-task) test_loss: 1.624163, test_acc: 0.565830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:13<00:00,  4.54s/it, epoch=5, train_loss=0.097, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.49it/s, epoch=5, train_loss=0.051, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 4 (meta-train-task) test_loss: 0.174749, test_acc: 0.588706\n",
      "# 4  (meta-test-task) test_loss: 1.602026, test_acc: 0.561053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:13<00:00,  4.55s/it, epoch=5, train_loss=0.086, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.53it/s, epoch=5, train_loss=0.057, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5 (meta-train-task) test_loss: 0.172007, test_acc: 0.595011\n",
      "# 5  (meta-test-task) test_loss: 1.572113, test_acc: 0.574413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:13<00:00,  4.55s/it, epoch=5, train_loss=0.099, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.52it/s, epoch=5, train_loss=0.056, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 6 (meta-train-task) test_loss: 0.168460, test_acc: 0.607895\n",
      "# 6  (meta-test-task) test_loss: 1.505896, test_acc: 0.611336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:12<00:00,  4.55s/it, epoch=5, train_loss=0.093, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.50it/s, epoch=5, train_loss=0.052, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 7 (meta-train-task) test_loss: 0.165030, test_acc: 0.626535\n",
      "# 7  (meta-test-task) test_loss: 1.491214, test_acc: 0.608178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:13<00:00,  4.55s/it, epoch=5, train_loss=0.088, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.50it/s, epoch=5, train_loss=0.048, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 8 (meta-train-task) test_loss: 0.162982, test_acc: 0.639090\n",
      "# 8  (meta-test-task) test_loss: 1.457721, test_acc: 0.620243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:12<00:00,  4.55s/it, epoch=5, train_loss=0.093, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.49it/s, epoch=5, train_loss=0.041, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 9 (meta-train-task) test_loss: 0.160618, test_acc: 0.643750\n",
      "# 9  (meta-test-task) test_loss: 1.433700, test_acc: 0.618785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 96/96 [07:12<00:00,  4.55s/it, epoch=5, train_loss=0.096, train_acc=1.000]\n",
      "Meta Test : 100%|█| 65/65 [00:18<00:00,  3.47it/s, epoch=5, train_loss=0.049, train_acc=1.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 10 (meta-train-task) test_loss: 0.157546, test_acc: 0.650548\n",
      "# 10  (meta-test-task) test_loss: 1.393006, test_acc: 0.637733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "meta_learner = MetaLearner()\n",
    "\n",
    "# see normal few-shot learning\n",
    "for _ in range(1):\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        0, test_loss, test_acc))\n",
    "\n",
    "#for epoch in range(1000):\n",
    "for epoch in range(10):\n",
    "    \n",
    "    train_loss, train_acc = meta_learner.meta_train()\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, test_loss, test_acc))\n",
    "    \n",
    "    model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "        epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "    meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_to",
   "language": "python",
   "name": "py36_to"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
