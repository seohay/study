{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find . -name '.DS_Store' -type f -ls -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from collections import OrderedDict\n",
    "from more_itertools import chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_shot = 1\n",
    "n_class = 10\n",
    "n_local_update = 5\n",
    "batch_size = n_class\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class OmniglotNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(OmniglotNet, self).__init__()\n",
    "        \n",
    "        self.h=64\n",
    "        self.conv1 = nn.Conv2d(1, self.h, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(self.h, self.h, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(self.h, momentum=1, affine=True)\n",
    "        self.fc = nn.Linear(self.h, n_class)\n",
    "        \n",
    "        # init is very very important!!!\n",
    "        # no init version -> HASH:ef56239\n",
    "        init.xavier_normal_(self.conv1.weight)\n",
    "        init.constant_(self.conv1.bias, 0)\n",
    "        init.xavier_normal_(self.conv2.weight)\n",
    "        init.constant_(self.conv2.bias, 0)\n",
    "        init.xavier_normal_(self.conv3.weight)\n",
    "        init.constant_(self.conv3.bias, 0)\n",
    "        \n",
    "        init.constant_(self.bn1.weight, 1)\n",
    "        init.constant_(self.bn1.bias, 0)\n",
    "        init.constant_(self.bn2.weight, 1)\n",
    "        init.constant_(self.bn2.bias, 0)\n",
    "        init.constant_(self.bn3.weight, 1)\n",
    "        init.constant_(self.bn3.bias, 0)\n",
    "        \n",
    "        init.normal_(self.fc.weight, 0, 0.01)\n",
    "        init.constant_(self.fc.bias, 1) # not 0 but 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)\n",
    "        x = F.max_pool2d(F.relu(self.bn3(self.conv3(x))), 2)\n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # for MAML local optimization\n",
    "    def manual_forward(self, x, params):\n",
    "        \n",
    "        x = F.conv2d(x, params['conv1.weight'].to(device), params['conv1.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn1.weight'], params['bn1.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv2.weight'].to(device), params['conv2.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn2.weight'], params['bn2.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = F.conv2d(x, params['conv3.weight'].to(device), params['conv3.bias'].to(device))\n",
    "        #dumy = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda()*999999999999999999 # momentnum=1\n",
    "        dumy = torch.ones(np.prod(np.array(x.data.size()[1])))*999999999999999999 # momentnum=1\n",
    "        x = F.batch_norm(x, dumy, dumy, params['bn3.weight'], params['bn3.bias'], True, momentum=1)\n",
    "        x = F.max_pool2d(F.relu(x), 2)\n",
    "        \n",
    "        x = x.view(x.size(0), self.h)\n",
    "        x = F.linear(x, params['fc.weight'].to(device), params['fc.bias'].to(device))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def train(model, device, train_data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for data, target in train_data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_data_loader.dataset)\n",
    "    train_acc /= len(train_data_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test(model, device, test_data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            test_loss += loss\n",
    "            test_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_data_loader.dataset)\n",
    "    test_acc /= len(test_data_loader.dataset)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedDataset(Dataset):\n",
    "    def __init__(self, path_to_chars, train, train_indices, transform):\n",
    "\n",
    "        self.data = []\n",
    "        self.path = NotImplementedError\n",
    "        \n",
    "        for label_i, (path_to_label, train_index) in enumerate(zip(path_to_chars, train_indices)):\n",
    "            chars = np.array(sorted(os.listdir(path_to_label)))#ある文字へのpath設定（ちなみにその中には20この画像）\n",
    "            if train:\n",
    "                chars = chars[train_index]#20画像のうちの1つを指定\n",
    "            else:#omniの一つの文字が20画像あるが、trainで使わなかったやつをtestにしている\n",
    "                test_index = list(set(np.arange(20)) - set(train_index)) # omniglot has 20 images per character\n",
    "                chars = chars[test_index]\n",
    "            for char in chars:\n",
    "                path_to_char = os.path.join(path_to_label, char)\n",
    "                image = io.imread(path_to_char)\n",
    "                label_i = np.array(label_i)\n",
    "                self.data.append([image, label_i])\n",
    "            \n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx])\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample[0], sample[1]\n",
    "        image = image / 255\n",
    "        image = (image-0.92208)/0.25140\n",
    "        image = image.reshape([28,28, 1])\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = np.array(image, np.float32)\n",
    "\n",
    "        return [torch.from_numpy(image), torch.from_numpy(label)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_task_train_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([8, 5, 2, 6, 0, 7, 4, 3, 1, 9])\n",
      "\n",
      "local_task_test_data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: tensor([1, 1, 0, 3, 4, 2, 2, 6, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 本番はいらない。チェック用。\n",
    "# 10文字指定したら\n",
    "\n",
    "#一つの文字に20画像あるうちtrainに使うindexを設定。適当な10文字をつかい、学習時は1文字中1つの画像しか見れな。\n",
    "# これはtrain時に見せる1/20とtest時の19/20を示す\n",
    "train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "\n",
    "#10文字を指定\n",
    "path_to_chars = [\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character08',\n",
    "    '../data/omniglot_mini/images_background/N_Ko/character05',\n",
    "    '../data/omniglot_mini/images_background/Early_Aramaic/character01',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character04',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character21',\n",
    "    '../data/omniglot_mini/images_background/Balinese/character03',\n",
    "    '../data/omniglot_mini/images_background/Gujarati/character35',\n",
    "    '../data/omniglot_mini/images_background/Bengali/character10',\n",
    "    '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character18',\n",
    "    '../data/omniglot_mini/images_background/Armenian/character17'\n",
    "]\n",
    "\n",
    "print(\"local_task_train_data\")\n",
    "local_task_train_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=True,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_train_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "\n",
    "print(\"\\nlocal_task_test_data\")\n",
    "local_task_test_data_loader = DataLoader(\n",
    "    OmniglotAugmentedDataset(path_to_chars,\n",
    "                    train=False,\n",
    "                    train_indices=train_indices,\n",
    "                    transform=transforms.Compose([\n",
    "                        ToTensor(),\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data, target in local_task_test_data_loader: # only have one batch\n",
    "    plt.figure(figsize=(10,1))\n",
    "    for i, x in enumerate(data):\n",
    "        plt.subplot(1, batch_size, i+1); plt.imshow(x[0])\n",
    "    plt.show()\n",
    "    print(\"y_true:\", target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taskset and TaskLoader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taskset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class TaskLoader(object):\n",
    "    def __init__(self, taskset, shuffle=True):\n",
    "        self.taskset = taskset\n",
    "        self.sample_iter = iter(np.random.permutation(np.arange(len(taskset))))\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        return self.taskset[next(self.sample_iter)]\n",
    "    def __len__(self):\n",
    "        return len(self.taskset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentedTaskset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotAugmentedTaskset(Taskset):\n",
    "    def __init__(self, path_to_omniglot, n_class, n_shot, meta_train):\n",
    "        \n",
    "        if meta_train:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_background/\")\n",
    "        else:\n",
    "            path_to_langs = os.path.join(path_to_omniglot, \"images_evaluation/\")\n",
    "            \n",
    "        chars = []\n",
    "        \n",
    "        for path_to_lang in os.listdir(path_to_langs):\n",
    "            path_to_chars = os.path.join(path_to_langs, path_to_lang)\n",
    "            for path_to_char in os.listdir(path_to_chars):\n",
    "                chars.append(os.path.join(path_to_chars, path_to_char)) \n",
    "        \n",
    "        random.shuffle(chars)\n",
    "        tasks = list(chunked(chars, n_class))[:-1] # drop_last\n",
    "        \n",
    "        self.tasks = tasks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        train_indices = np.random.randint(20, size=(n_class, n_shot))\n",
    "        return {\"train\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=True,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True), \n",
    "                \"test\":\n",
    "                DataLoader(\n",
    "                    OmniglotAugmentedDataset(self.tasks[idx],\n",
    "                                    train=False,\n",
    "                                    train_indices=train_indices,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        ToTensor()\n",
    "                                    ])),\n",
    "                    batch_size=batch_size, shuffle=True),\n",
    "                \"task\": self.tasks[idx] \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AugmentTaskLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['../data/omniglot_mini/images_background/Latin/character05', '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character10', '../data/omniglot_mini/images_background/Hebrew/character10', '../data/omniglot_mini/images_background/Bengali/character39', '../data/omniglot_mini/images_background/N_Ko/character12', '../data/omniglot_mini/images_background/Balinese/character17', '../data/omniglot_mini/images_background/Burmese_(Myanmar)/character25', '../data/omniglot_mini/images_background/Mkhedruli_(Georgian)/character13', '../data/omniglot_mini/images_background/Anglo-Saxon_Futhorc/character12', '../data/omniglot_mini/images_background/Cyrillic/character20']\n",
      "train\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 5, 7, 6, 3, 8, 0, 4, 2, 1])\n",
      "test\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 6, 5, 9, 5, 9, 5, 0, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "meta_train_task_loader = TaskLoader(\n",
    "    OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot)\n",
    ")\n",
    "\n",
    "print(len(meta_train_task_loader.taskset))\n",
    "\n",
    "for i, meta_train_task in enumerate(meta_train_task_loader):\n",
    "    print(meta_train_task[\"task\"])\n",
    "    print(\"train\")\n",
    "    local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "    for data, target in local_task_train_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "    print(\"test\")\n",
    "    local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "    for data, target in local_task_test_data_loader:\n",
    "        plt.figure(figsize=(10,1))\n",
    "        for j, x in enumerate(data):\n",
    "            plt.subplot(1, batch_size, j+1); plt.imshow(x[0])\n",
    "        plt.show()\n",
    "        print(target)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.1\n",
    "        self.momentum = 0.5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.master_net = OmniglotNet(n_class).to(self.device)\n",
    "        self.master_opt = optim.Adam(self.master_net.parameters(), lr=0.001)\n",
    "        self.keys = self.master_net.state_dict().keys()\n",
    "    \n",
    "    def copy_params(self, from_net, to_net):\n",
    "        params = {k: v for k, v in from_net.state_dict().items() if k in self.keys}\n",
    "        to_net.load_state_dict(params, strict=False)\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.master_net.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.master_net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def meta_test(self):\n",
    "        \n",
    "        meta_test_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=False, n_class=n_class, n_shot=n_shot))\n",
    "\n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_test_task_loader, desc=\"Meta Test \", ncols=10) as _tqdm:\n",
    "            for meta_test_task in _tqdm:\n",
    "\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "                faster_opt = optim.SGD(faster_net.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_test_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_test_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    _train_loss, _train_acc = train(\n",
    "                        faster_net, self.device, local_task_train_data_loader, faster_opt, epoch)\n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task test\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                _test_loss, _test_acc = test(faster_net, self.device, local_task_test_data_loader)\n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        return np.mean(test_loss), np.mean(test_acc)\n",
    "\n",
    "    \n",
    "    def meta_train(self):\n",
    "        \n",
    "        meta_train_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=n_shot))\n",
    "    \n",
    "        meta_grads = []\n",
    "        \n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_train_task_loader, desc=\"Meta Train\", ncols=10) as _tqdm:\n",
    "            for meta_train_task in _tqdm:\n",
    "                meta_train_task = _tqdm\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                faster_net.forward = NotImplementedError # goodbye!\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "\n",
    "                # faster_params = OrderedDict((name, param) for (name, param) in faster_net.named_parameters())\n",
    "                master_params = OrderedDict((name, param) for (name, param) in self.master_net.named_parameters())\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                first_train_for_this_task = True\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    \n",
    "                    _train_loss = 0 # For tqdm.\n",
    "                    _train_acc = 0 # For tqdm.\n",
    "                    \n",
    "                    for data, target in local_task_train_data_loader:\n",
    "                        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                        if first_train_for_this_task:\n",
    "                            # manual predict\n",
    "                            output = self.master_net(data)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "                            grads = torch.autograd.grad(loss, self.master_net.parameters(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(master_params.items(), grads)\n",
    "                            )\n",
    "                            \n",
    "                            first_train_for_this_task = False\n",
    "\n",
    "                        else:\n",
    "                            # manual predict\n",
    "                            output = faster_net.manual_forward(data, faster_params)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                                                        \n",
    "                            grads = torch.autograd.grad(loss, faster_params.values(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "                            )\n",
    "\n",
    "                    _train_loss /= len(local_task_train_data_loader.dataset)\n",
    "                    _train_acc /= len(local_task_train_data_loader.dataset)\n",
    "                    \n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                \n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task test\n",
    "                # ----------------------------------------------------------------\n",
    "                \n",
    "                _test_loss = 0 # For logging.\n",
    "                _test_acc = 0 # For logging.\n",
    "                \n",
    "                for data, target in local_task_test_data_loader:\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                    output = faster_net.manual_forward(data, faster_params)\n",
    "                    loss = F.nll_loss(output, target) # test_loss計算するとこまではfaster_net\n",
    "\n",
    "                    # differentiates test_loss by master_net params\n",
    "                    grads = torch.autograd.grad(loss, self.master_net.parameters(), retain_graph=True)\n",
    "                    grads = {name:g for ((name, _), g) in zip(faster_net.named_parameters(), grads)}\n",
    "                    meta_grads.append(grads)\n",
    "\n",
    "                    pred = output.max(1, keepdim=True)[1]\n",
    "                    acc = pred.eq(target.view_as(pred)).sum()\n",
    "                    \n",
    "                    _test_loss += loss.item()\n",
    "                    _test_acc += acc.item()\n",
    "                \n",
    "                _test_loss /= len(local_task_test_data_loader.dataset)\n",
    "                _test_acc /= len(local_task_test_data_loader.dataset)  \n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # end all tasks\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # meta update\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        meta_grads = {k: sum(grads[k] for grads in meta_grads) for k in meta_grads[0].keys()}\n",
    "        \n",
    "        # using data,target from somewhere\n",
    "        dumy_output = self.master_net(data)\n",
    "        dumy_loss = F.nll_loss(dumy_output, target)\n",
    "        \n",
    "        # after dumy_loss.backward, rewrite grads\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward(retain_graph=True)\n",
    "\n",
    "        hooks = []\n",
    "        for (k,v) in self.master_net.named_parameters():\n",
    "            def get_closure():\n",
    "                key = k\n",
    "                def replace_grad(grad):\n",
    "                    return meta_grads[key]\n",
    "                return replace_grad\n",
    "            hooks.append(v.register_hook(get_closure()))\n",
    "\n",
    "        # Compute grads for current step, replace with summed gradients as defined by hook\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward()\n",
    "\n",
    "        # Update the net parameters with the accumulated gradient according to optimizer\n",
    "        self.master_opt.step()\n",
    "\n",
    "        # Remove the hooks before next training phase\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        return np.mean(test_loss), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.73it/s, epoch=5, train_loss=0.038, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  (meta-test-task) test_loss: 1.834354, test_acc: 0.463158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:13<00:00,  4.54s/it, epoch=5, train_loss=0.121, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.84it/s, epoch=5, train_loss=0.055, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 (meta-train-task) test_loss: 0.204827, test_acc: 0.354386\n",
      "# 1  (meta-test-task) test_loss: 1.822707, test_acc: 0.421053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:13<00:00,  4.47s/it, epoch=5, train_loss=0.111, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.83it/s, epoch=5, train_loss=0.040, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2 (meta-train-task) test_loss: 0.199044, test_acc: 0.443860\n",
      "# 2  (meta-test-task) test_loss: 1.758214, test_acc: 0.457895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:13<00:00,  4.56s/it, epoch=5, train_loss=0.111, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.76it/s, epoch=5, train_loss=0.055, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3 (meta-train-task) test_loss: 0.198220, test_acc: 0.415789\n",
      "# 3  (meta-test-task) test_loss: 1.772604, test_acc: 0.463158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:13<00:00,  4.60s/it, epoch=5, train_loss=0.108, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.82it/s, epoch=5, train_loss=0.063, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 4 (meta-train-task) test_loss: 0.191238, test_acc: 0.459649\n",
      "# 4  (meta-test-task) test_loss: 1.728174, test_acc: 0.478947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:14<00:00,  4.83s/it, epoch=5, train_loss=0.086, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.80it/s, epoch=5, train_loss=0.060, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 5 (meta-train-task) test_loss: 0.182826, test_acc: 0.491228\n",
      "# 5  (meta-test-task) test_loss: 1.849643, test_acc: 0.357895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:14<00:00,  4.69s/it, epoch=5, train_loss=0.099, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.62it/s, epoch=5, train_loss=0.056, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 6 (meta-train-task) test_loss: 0.183468, test_acc: 0.524561\n",
      "# 6  (meta-test-task) test_loss: 1.760758, test_acc: 0.436842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:14<00:00,  4.70s/it, epoch=5, train_loss=0.089, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.63it/s, epoch=5, train_loss=0.051, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 7 (meta-train-task) test_loss: 0.181536, test_acc: 0.475439\n",
      "# 7  (meta-test-task) test_loss: 1.794412, test_acc: 0.478947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:14<00:00,  4.76s/it, epoch=5, train_loss=0.096, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.78it/s, epoch=5, train_loss=0.057, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 8 (meta-train-task) test_loss: 0.179658, test_acc: 0.512281\n",
      "# 8  (meta-test-task) test_loss: 1.568417, test_acc: 0.631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:14<00:00,  4.72s/it, epoch=5, train_loss=0.100, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.80it/s, epoch=5, train_loss=0.057, train_acc=1.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 9 (meta-train-task) test_loss: 0.172824, test_acc: 0.607018\n",
      "# 9  (meta-test-task) test_loss: 1.757966, test_acc: 0.468421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train: 100%|█| 3/3 [00:13<00:00,  4.50s/it, epoch=5, train_loss=0.088, train_acc=1.000]\n",
      "Meta Test : 100%|█| 1/1 [00:00<00:00,  3.84it/s, epoch=5, train_loss=0.058, train_acc=1.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 10 (meta-train-task) test_loss: 0.177528, test_acc: 0.514035\n",
      "# 10  (meta-test-task) test_loss: 1.622891, test_acc: 0.547368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "meta_learner = MetaLearner()\n",
    "\n",
    "# see normal few-shot learning\n",
    "for _ in range(1):\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        0, test_loss, test_acc))\n",
    "\n",
    "#for epoch in range(1000):\n",
    "for epoch in range(10):\n",
    "    \n",
    "    train_loss, train_acc = meta_learner.meta_train()\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, test_loss, test_acc))\n",
    "    \n",
    "    model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "        epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "    meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineLearner(object):\n",
    "    def __init__(self):\n",
    "        self.lr = 0.1\n",
    "        self.momentum = 0.5\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.master_net = OmniglotNet(n_class).to(self.device)\n",
    "        self.master_opt = optim.Adam(self.master_net.parameters(), lr=0.001)\n",
    "        self.keys = self.master_net.state_dict().keys()\n",
    "    \n",
    "    def copy_params(self, from_net, to_net):\n",
    "        params = {k: v for k, v in from_net.state_dict().items() if k in self.keys}\n",
    "        to_net.load_state_dict(params, strict=False)\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.master_net.state_dict(), model_path)\n",
    "    \n",
    "    def load(self, model_path):\n",
    "        self.master_net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    def meta_test(self):\n",
    "        \n",
    "        meta_test_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=False, n_class=n_class, n_shot=n_shot))\n",
    "\n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_test_task_loader, desc=\"Meta Test \", ncols=10) as _tqdm:\n",
    "            for meta_test_task in _tqdm:\n",
    "\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "                faster_opt = optim.SGD(faster_net.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_test_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_test_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    _train_loss, _train_acc = train(\n",
    "                        faster_net, self.device, local_task_train_data_loader, faster_opt, epoch)\n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta test task test\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                _test_loss, _test_acc = test(faster_net, self.device, local_task_test_data_loader)\n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        return np.mean(test_loss), np.mean(test_acc)\n",
    "\n",
    "    \n",
    "    def meta_train(self):\n",
    "        \n",
    "        meta_train_task_loader = TaskLoader(\n",
    "            OmniglotAugmentedTaskset(\"../data/omniglot_mini/\", meta_train=True, n_class=n_class, n_shot=6))\n",
    "    \n",
    "        meta_grads = []\n",
    "        \n",
    "        test_loss, test_acc = [], [] # For logging.\n",
    "        \n",
    "        sleep(0.5)\n",
    "        with tqdm(meta_train_task_loader, desc=\"Meta Train\", ncols=10) as _tqdm:\n",
    "            for meta_train_task in _tqdm:\n",
    "                #meta_train_task = _tqdm[0]\n",
    "                # copy master model to new branch model\n",
    "                faster_net = OmniglotNet(n_class).to(self.device)\n",
    "                faster_net.forward = NotImplementedError # goodbye!\n",
    "                self.copy_params(self.master_net, faster_net)\n",
    "\n",
    "                # faster_params = OrderedDict((name, param) for (name, param) in faster_net.named_parameters())\n",
    "                master_params = OrderedDict((name, param) for (name, param) in self.master_net.named_parameters())\n",
    "\n",
    "                # make local task data loader\n",
    "                local_task_train_data_loader = meta_train_task[\"train\"]\n",
    "                local_task_test_data_loader = meta_train_task[\"test\"]\n",
    "\n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task train\n",
    "                # ----------------------------------------------------------------\n",
    "\n",
    "                first_train_for_this_task = True\n",
    "\n",
    "                for epoch in range(n_local_update):\n",
    "                    \n",
    "                    _train_loss = 0 # For tqdm.\n",
    "                    _train_acc = 0 # For tqdm.\n",
    "                    \n",
    "                    for data, target in local_task_train_data_loader:\n",
    "                        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                        if first_train_for_this_task:\n",
    "                            # manual predict\n",
    "                            output = self.master_net(data)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                            \n",
    "                            grads = torch.autograd.grad(loss, self.master_net.parameters(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(master_params.items(), grads)\n",
    "                            )\n",
    "                            \n",
    "                            first_train_for_this_task = False\n",
    "\n",
    "                        else:\n",
    "                            # manual predict\n",
    "                            output = faster_net.manual_forward(data, faster_params)\n",
    "                            loss = F.nll_loss(output, target)\n",
    "                            pred = output.max(1, keepdim=True)[1]\n",
    "                            \n",
    "                            _train_loss += loss\n",
    "                            _train_acc += pred.eq(target.view_as(pred)).sum().item()\n",
    "                                                        \n",
    "                            grads = torch.autograd.grad(loss, faster_params.values(), create_graph=True)\n",
    "\n",
    "                            faster_params = OrderedDict(\n",
    "                                (name, param - self.lr*grad)\n",
    "                                for ((name, param), grad) in zip(faster_params.items(), grads)\n",
    "                            )\n",
    "\n",
    "                    _train_loss /= len(local_task_train_data_loader.dataset)\n",
    "                    _train_acc /= len(local_task_train_data_loader.dataset)\n",
    "                    \n",
    "                    _tqdm.set_postfix(OrderedDict(\n",
    "                        epoch=epoch+1, \n",
    "                        train_loss=\"{:.3f}\".format(_train_loss), \n",
    "                        train_acc=\"{:.3f}\".format(_train_acc)))\n",
    "                \n",
    "                # ----------------------------------------------------------------\n",
    "                # meta train task test\n",
    "                # ----------------------------------------------------------------\n",
    "                \n",
    "                _test_loss = 0 # For logging.\n",
    "                _test_acc = 0 # For logging.\n",
    "                \n",
    "                for data, target in local_task_test_data_loader:\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "                    output = faster_net.manual_forward(data, faster_params)\n",
    "                    loss = F.nll_loss(output, target) # test_loss計算するとこまではfaster_net\n",
    "\n",
    "                    # differentiates test_loss by master_net params\n",
    "                    grads = torch.autograd.grad(loss, self.master_net.parameters(), retain_graph=True)\n",
    "                    grads = {name:g for ((name, _), g) in zip(faster_net.named_parameters(), grads)}\n",
    "                    meta_grads.append(grads)\n",
    "\n",
    "                    pred = output.max(1, keepdim=True)[1]\n",
    "                    acc = pred.eq(target.view_as(pred)).sum()\n",
    "                    \n",
    "                    _test_loss += loss.item()\n",
    "                    _test_acc += acc.item()\n",
    "                \n",
    "                _test_loss /= len(local_task_test_data_loader.dataset)\n",
    "                _test_acc /= len(local_task_test_data_loader.dataset)  \n",
    "                test_loss.append(_test_loss)\n",
    "                test_acc.append(_test_acc)\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # end all tasks\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        # ----------------------------------------------------------------\n",
    "        # meta update\n",
    "        # ----------------------------------------------------------------\n",
    "        \n",
    "        meta_grads = {k: sum(grads[k] for grads in meta_grads) for k in meta_grads[0].keys()}\n",
    "        \n",
    "        # using data,target from somewhere\n",
    "        dumy_output = self.master_net(data)\n",
    "        dumy_loss = F.nll_loss(dumy_output, target)\n",
    "        \n",
    "        # after dumy_loss.backward, rewrite grads\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward(retain_graph=True)\n",
    "\n",
    "        hooks = []\n",
    "        for (k,v) in self.master_net.named_parameters():\n",
    "            def get_closure():\n",
    "                key = k\n",
    "                def replace_grad(grad):\n",
    "                    return meta_grads[key]\n",
    "                return replace_grad\n",
    "            hooks.append(v.register_hook(get_closure()))\n",
    "\n",
    "        # Compute grads for current step, replace with summed gradients as defined by hook\n",
    "        self.master_opt.zero_grad()\n",
    "        dumy_loss.backward()\n",
    "\n",
    "        # Update the net parameters with the accumulated gradient according to optimizer\n",
    "        self.master_opt.step()\n",
    "\n",
    "        # Remove the hooks before next training phase\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "        return np.mean(test_loss), np.mean(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Meta Train:   0%| | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tqdm' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-88bf9afe6c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-d43247aa8912>\u001b[0m in \u001b[0;36mmeta_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# make local task data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mlocal_task_train_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_train_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mlocal_task_test_data_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_train_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tqdm' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "meta_learner = FineLearner()\n",
    "\n",
    "#for epoch in range(1000):\n",
    "for epoch in range(10):\n",
    "    \n",
    "    train_loss, train_acc = meta_learner.meta_train()\n",
    "    test_loss, test_acc = meta_learner.meta_test()\n",
    "    \n",
    "    print(\"# {} (meta-train-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, train_loss, train_acc))    \n",
    "    print(\"# {}  (meta-test-task) test_loss: {:.6f}, test_acc: {:.6f}\".format(\n",
    "        epoch+1, test_loss, test_acc))\n",
    "    \n",
    "    model_path = \"../model/model-epoch_{:05}-train_loss_{:0.3f}-train_acc_{:0.3f}-test_loss_{:0.3f}-test_acc_{:0.3f}.pt\".format(\n",
    "        epoch, train_loss, train_acc, test_loss, test_acc)\n",
    "    \n",
    "    meta_learner.save(model_path)\n",
    "#     meta_learner.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_to",
   "language": "python",
   "name": "py36_to"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
