{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prep.ipynbで作成した入力データを用いて実際に学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# 説明変数用\n",
    "###########################################\n",
    "\n",
    "# 短時間フーリエ変換\n",
    "def stft_core(x, win, step,IMG_SIZE):\n",
    "    l = len(x) # 入力信号の長さ\n",
    "    N = len(win) # 窓幅\n",
    "    M = int(np.ceil(float(l - N + step) / step)) # スペクトログラムの時間フレーム数\n",
    "    \n",
    "    new_x = np.zeros(N + ((M - 1) * int(step)), dtype = float)\n",
    "    new_x[: l] = x # 信号をいい感じの長さにする\n",
    "    \n",
    "    X = np.zeros([M, N], dtype = complex) # スペクトログラムの初期化(複素数型)\n",
    "    X2 = np.zeros([(M-M%IMG_SIZE+IMG_SIZE), N], dtype = complex) # あとで使う\n",
    "    \n",
    "    for m in range(M):\n",
    "        start = int(step * m)\n",
    "        X[m, :] = np.fft.fft(new_x[start : start + N] * win)\n",
    "        X2[m, :] = np.fft.fft(new_x[start : start + N] * win)\n",
    "    return X,X2\n",
    "\n",
    "\n",
    "def stft(filename,IMG_SIZE):\n",
    "    # file read\n",
    "    wf = wave.open(filename , \"r\" )\n",
    "    fs = wf.getframerate()  # サンプリング周波数\n",
    "    g = wf.readframes(wf.getnframes())\n",
    "    wf.close()\n",
    "\n",
    "    # -1～1に正規化\n",
    "    g = np.frombuffer(g, dtype= \"int16\")/32768.0    \n",
    "\n",
    "    fftLen = (IMG_SIZE-1)*2\n",
    "    win = np.hamming(fftLen) # ハミング窓\n",
    "    step = fftLen / 2                 \n",
    "\n",
    "    spectrogram,spectrogram2 = stft_core(g, win, step,IMG_SIZE)\n",
    "\n",
    "    return spectrogram2, fftLen\n",
    "\n",
    "# 説明変数計算\n",
    "def calc_data(spectrogram2, fftLen,IMG_SIZE):\n",
    "    #\"\"\"\n",
    "    def min_max_normalixstion(x):\n",
    "        x_min = x.min()\n",
    "        x_max = x.max()\n",
    "        x_norm = ((x-x_min)/(x_max - x_min)*255).astype(\"uint8\")\n",
    "        return x_norm\n",
    "    \"\"\"\n",
    "    def min_max_normalixstion(x):\n",
    "        return x\n",
    "    \"\"\"\n",
    "\n",
    "    data_tmp = min_max_normalixstion(abs(spectrogram2[:, : int(fftLen / 2 + 1)]))\n",
    "    data = data_tmp.reshape(int((len(data_tmp)*IMG_SIZE)/(IMG_SIZE*IMG_SIZE)),IMG_SIZE,IMG_SIZE)\n",
    "    \n",
    "    data = data.reshape(data.shape[0],data.shape[1],data.shape[2],1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# 目的変数用\n",
    "###########################################\n",
    "\n",
    "# 目的変数計算\n",
    "def calc_target(ydata_tmp,fftLen,data):\n",
    "    ydata_ft = []\n",
    "    for i in range(len(ydata_tmp)):\n",
    "        ydata_ft.append(int(ydata_tmp[i]/fftLen*2))\n",
    "     \n",
    "    target = np.zeros([int(len(data)),2], dtype = \"uint8\")\n",
    "    target[:,0]=1\n",
    "    \n",
    "    for i in range(len(ydata_ft)):\n",
    "        tmp = int(ydata_ft[i]/256)\n",
    "        target[tmp][0]=0\n",
    "        target[tmp][1]=1\n",
    "    \n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# CNN用\n",
    "###########################################\n",
    "\n",
    "# 畳み込み\n",
    "class Conv:\n",
    "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
    "        # Xavier Initialization\n",
    "        fan_in = np.prod(filter_shape[:3]) #配列の最初の３つの積\n",
    "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/(fan_in + fan_out)),\n",
    "                        high=np.sqrt(6/(fan_in + fan_out)),\n",
    "                        size=filter_shape\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b') \n",
    "        self.function = function\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
    "        return self.function(u)\n",
    "    \n",
    "# プーリング\n",
    "class Pooling:\n",
    "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    \n",
    "    def f_prop(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
    "\n",
    "# 平滑化\n",
    "class Flatten:\n",
    "    def f_prop(self, x):\n",
    "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
    "\n",
    "# 全結合\n",
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        # Xavier Initialization\n",
    "        self.W = tf.Variable(rng.uniform(\n",
    "                        low=-np.sqrt(6/(in_dim + out_dim)),\n",
    "                        high=np.sqrt(6/(in_dim + out_dim)),\n",
    "                        size=(in_dim, out_dim)\n",
    "                    ).astype('float32'), name='W')\n",
    "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
    "        self.function = function\n",
    "\n",
    "    def f_prop(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)\n",
    "    \n",
    "    \n",
    "def cnn(n_epochs, batch_size, n_batches, train_x, valid_x, train_y, valid_y,IMG_SIZE):\n",
    "\n",
    "    layers = [                            \n",
    "        Conv((5, 5, 1, 20), tf.nn.relu),  \n",
    "        Pooling((1, 2, 2, 1)),            \n",
    "        Conv((5, 5, 20, 50), tf.nn.relu), \n",
    "        Pooling((1, 2, 2, 1)),            \n",
    "\n",
    "        Flatten(),\n",
    "        Dense(int(((IMG_SIZE-4)/2-4)/2)*int(((IMG_SIZE-4)/2-4)/2)*50, 2, tf.nn.softmax)\n",
    "    ]\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, IMG_SIZE, IMG_SIZE, 1])\n",
    "    t = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "    def f_props(layers, x):\n",
    "        for layer in layers:\n",
    "            x = layer.f_prop(x)\n",
    "        return x\n",
    "\n",
    "    y = f_props(layers, x)\n",
    "\n",
    "    cost = -tf.reduce_mean(tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)), axis=1)) # tf.log(0)によるnanを防ぐ\n",
    "    train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "    valid = tf.argmax(y, 1)\n",
    "\n",
    "    \n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(n_epochs):\n",
    "            train_x, train_y = shuffle(train_x, train_y, random_state=random_state)\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "                sess.run(train, feed_dict={x: train_x[start:end], t: train_y[start:end]})\n",
    "\n",
    "            pred_y, valid_cost = sess.run([valid, cost], feed_dict={x: valid_x, t: valid_y})\n",
    "            print('EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' % (epoch + 1, valid_cost, f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')))\n",
    "            val = f1_score(np.argmax(valid_y, 1).astype('int32'), pred_y, average='macro')\n",
    "            \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# ベイズ最適化で調べる関数\n",
    "###########################################\n",
    "def func(IMG_SIZE, n_epochs, batch_size):\n",
    "    \n",
    "    #入力ファイル\n",
    "    filename = \"sound1.wav\"\n",
    "    #上記入力ファイルを入れたときの求める音が発生した位置\n",
    "    ydata_tmp = [228438,262174,320607,355446,648711,677596,726768,780349,802840,846279,1189377,1212529,1253101,1286397,1315282,\n",
    "    1677564,1712623,1762456,1822212,1853743,1884834,1919673,2210953,2250864,2291877,2344797,2377210,2709283,2754706,2802775,\n",
    "    2841583,2871792,2910379,2933311,2974324,3008061,3068478,3096261,3143889,3176082,3243114,3285891,3633399,3664269,3728434,\n",
    "    4116514,4151353,4208463,4510107,4540536,4599850,4677687,4709439,4763461,5077894,5111851,5162125,5207548,5239962,5543370,\n",
    "    5575342,5952397,5983488,6035967,6383034,6418755,6464178,6506073,6533856,6570459,6613897,6660423,6693939,6736054,7028217,\n",
    "    7066363,7119283,7171321,7463263,7495897,7558519,7627315,7693465,7721910,7988935,8020908,8079561,8128732,8152105,8198631,\n",
    "    8223988,8288374,8351878,8395978,8799052,8838081,8879976,9198378,9235422,9278640,9344128,9406089,9443133,9474885,9508180,\n",
    "    9545886,9821731,9853263,9889425,10232302,10263393,10305288,10366587,10396134,10447731,10479483]\n",
    "\n",
    "    IMG_SIZE = int(IMG_SIZE)#32#64#128\n",
    "    n_epochs = int(n_epochs)#1#10\n",
    "    batch_size = int(batch_size)#100    \n",
    "\n",
    "    # 説明変数計算\n",
    "    spectrogram2, fftLen = stft(filename,IMG_SIZE)\n",
    "    data = calc_data(spectrogram2, fftLen,IMG_SIZE)\n",
    "\n",
    "    # 目的変数計算\n",
    "    target = calc_target(ydata_tmp,fftLen,data)\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.3, random_state=42)\n",
    "\n",
    "    n_batches = train_x.shape[0]//batch_size\n",
    "    val = cnn(n_epochs, batch_size, n_batches, train_x, valid_x, train_y, valid_y,IMG_SIZE)\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sn/.pyenv/versions/anaconda3-5.0.1/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/sn/BayesianOptimization_bayes_opt')\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   IMG_SIZE |   batch_size |   n_epochs | \n",
      "EPOCH:: 1, Validation cost: 0.023, Validation F1: 0.499\n",
      "    1 | 01m11s | \u001b[35m   0.49913\u001b[0m | \u001b[32m   32.0000\u001b[0m | \u001b[32m     10.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \n",
      "EPOCH:: 1, Validation cost: 3.376, Validation F1: 0.459\n",
      "EPOCH:: 2, Validation cost: 3.146, Validation F1: 0.459\n",
      "    2 | 01m18s |    0.45946 |   256.0000 |     100.0000 |     2.0000 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   IMG_SIZE |   batch_size |   n_epochs | \n",
      "EPOCH:: 1, Validation cost: 0.042, Validation F1: 0.499\n",
      "EPOCH:: 2, Validation cost: 0.040, Validation F1: 0.499\n",
      "EPOCH:: 3, Validation cost: 0.036, Validation F1: 0.499\n",
      "    3 | 01m59s |    0.49913 |    32.0000 |     100.0000 |     3.0000 | \n",
      "EPOCH:: 1, Validation cost: 0.043, Validation F1: 0.499\n",
      "    4 | 01m13s |    0.49913 |    32.0292 |      96.9750 |     1.1615 | \n",
      "-----------------------------------------------------\n",
      "Final Results\n",
      "func: 0.499127\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# ベイズ最適化で実際に調べる\n",
    "###########################################\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    funcBO = BayesianOptimization(\n",
    "        func,                            # ブラックボックス関数\n",
    "        pbounds = {\n",
    "                    'IMG_SIZE': (32,256),\n",
    "                    'n_epochs': (1,3),\n",
    "                    'batch_size': (10,100),\n",
    "                  },\n",
    "        verbose = 1\n",
    "                                ) \n",
    "\n",
    "    funcBO.explore({'IMG_SIZE': [32,256],'n_epochs': [1,2],'batch_size': [10,100]}) # 初期の探索位置\n",
    "\n",
    "    funcBO.maximize(\n",
    "        init_points = 0, # 最初にしておく数, 初期試行回数は3くらいがいい\n",
    "        n_iter=2, # 何回評価するか\n",
    "        acq = \"ei\", # 獲得関数: poi, ei, ucb\n",
    "        kernel = RBF(2) # カーネル関数: matern5/2\n",
    "        )\n",
    "\n",
    "    print('-' * 53)\n",
    "    print('Final Results')\n",
    "    print('func: %f' % funcBO.res['max']['max_val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
